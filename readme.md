# ğŸ“š Evaluating Word Embeddings in Fictional Narratives

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)  
[![Jupyter Notebook](https://img.shields.io/badge/Jupyter_Notebook-%F0%9F%93%96-orange)](https://jupyter.org/)  

### ğŸš€ A Comparative Study of Word2Vec, FastText, and GloVe in Literary Text Analysis

This repository provides a **Jupyter Notebook implementation** of a research study comparing **Word2Vec, FastText, and GloVe** for analyzing **fictional narratives**. The code processes text from **epic, fantasy, and detective fiction** to examine how these word embeddings handle **semantic relationships, analogy tasks, and word clustering**.

---

## ğŸ“Œ Features
âœ… **Preprocesses Fictional Text** â€“ Tokenization, stopword removal, lemmatization  
âœ… **Trains Word2Vec & FastText Models** â€“ Captures semantic meaning from text  
âœ… **Loads Pretrained GloVe Vectors** â€“ Uses Stanford's 100D embeddings  
âœ… **Evaluates Cosine Similarity** â€“ Measures semantic closeness of words  
âœ… **Performs Analogy Tasks** â€“ Tests conceptual relationships between words  
âœ… **Visualizes Embeddings (PCA/t-SNE)** â€“ Shows word clusters in 2D space  
âœ… **Computes Clustering Quality (Silhouette Score)** â€“ Evaluates embedding effectiveness  

---

## ğŸ“‚ Repository Structure

```bash
ğŸ“‚ word-embeddings-fiction
â”‚â”€â”€ ğŸ“œ README.md            # Documentation for the repository
â”‚â”€â”€ ğŸ“œ requirements.txt      # List of required Python dependencies
â”‚â”€â”€ ğŸ“œ word_embeddings.ipynb # Jupyter Notebook with full implementation
â”‚â”€â”€ ğŸ“œ glove.6B.100d.txt     # Pretrained GloVe embeddings (downloaded)
â”‚â”€â”€ ğŸ“œ word2vec_fiction.model # Saved Word2Vec model
â”‚â”€â”€ ğŸ“œ fasttext_fiction.model # Saved FastText model
```
## ğŸ”§ Installation & Setup

### 1ï¸âƒ£ **Clone the Repository**
Clone the GitHub repository to your local system:
```bash
git clone https://github.com/vrundag91/Evaluation-of-the-performance-of-word-embeddings-in-fictional-narratives.git
cd word-embeddings-fiction
```
###2ï¸âƒ£ **Create a Virtual Environment (Optional but Recommended)**
```bash
python3 -m venv env
source env/bin/activate  # For Mac/Linux
env\Scripts\activate     # For Windows
```
### 3ï¸âƒ£ **Install Required Dependencies**
```bash
pip install -r requirements.txt
```
### 4ï¸âƒ£ **Download & Extract Pretrained GloVe Embeddings**
Run the following command inside a Python script or Jupyter Notebook:
```bash
import urllib.request
import zipfile

glove_url = "http://nlp.stanford.edu/data/glove.6B.zip"
urllib.request.urlretrieve(glove_url, "glove.6B.zip")

with zipfile.ZipFile("glove.6B.zip", 'r') as zip_ref:
    zip_ref.extractall("glove_data")

print("GloVe embeddings downloaded and extracted!")

```

## ğŸ“Š Key Findings

1ï¸âƒ£ **FastText performs best for fictional text** as it handles **rare words & invented vocabulary** (e.g., *"Muggle"* in Harry Potter).  
2ï¸âƒ£ **Word2Vec is effective for structured texts** but struggles with **out-of-vocabulary (OOV) words**.  
3ï¸âƒ£ **GloVe performs well on general NLP tasks** but lacks **genre-specific adaptability** for fiction.  
4ï¸âƒ£ **FastText produces better-defined clusters** in **t-SNE and PCA visualizations**.  
5ï¸âƒ£ **Silhouette Score confirms FastText forms stronger semantic clusters** compared to Word2Vec & GloVe.  


